# GPT-4.1 Prompting Guide

## Description
Comprehensive official prompting guide for GPT-4.1 family models, representing a significant step forward from GPT-4o in capabilities across coding, instruction following, and long context. This guide collates important prompting tips derived from extensive internal testing to help developers fully leverage the improved abilities of this new model family.

## Source
OpenAI Official Documentation - GPT-4.1 Prompting Guide

## Overview

GPT-4.1 is trained to follow instructions more closely and more literally than its predecessors, which tended to more liberally infer intent from user and system prompts. This means GPT-4.1 is highly steerable and responsive to well-specified prompts - if model behavior is different from what you expect, a single sentence firmly and unequivocally clarifying your desired behavior is almost always sufficient to steer the model on course.

**Key Characteristics:**
- More literal instruction following
- Highly steerable with precise prompts
- Improved agentic capabilities
- Enhanced long context performance (1M tokens)
- Better tool utilization

---

## 1. Agentic Workflows

GPT-4.1 is excellent for building agentic workflows. The model achieves state-of-the-art performance for non-reasoning models on SWE-bench Verified, solving 55% of problems.

### System Prompt Reminders

Include these three key types of reminders in all agent prompts:

#### 1. Persistence
```
You are an agent - please keep going until the user's query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved.
```

#### 2. Tool-calling
```
If you are not sure about file content or codebase structure pertaining to the user's request, use your tools to read files and gather the relevant information: do NOT guess or make up an answer.
```

#### 3. Planning [Optional]
```
You MUST plan extensively before each function call, and reflect extensively on the outcomes of the previous function calls. DO NOT do this entire process by making function calls only, as this can impair your ability to solve the problem and think insightfully.
```

**Impact**: These three instructions increased internal SWE-bench Verified score by close to 20%.

### Tool Calls Best Practices

- **Use API tools field exclusively** rather than manually injecting tool descriptions
- **Name tools clearly** to indicate their purpose
- **Add detailed descriptions** in the "description" field
- **Use good naming and descriptions** for each tool parameter
- **Place examples in system prompt** rather than description field if needed

**Performance Impact**: Using API-parsed tool descriptions vs manually injecting schemas increased SWE-bench Verified pass rate by 2%.

### Prompting-Induced Planning & Chain-of-Thought

GPT-4.1 is not a reasoning model but can be prompted to plan and reflect between tool calls. Inducing explicit planning increased pass rate by 4% in SWE-bench Verified testing.

### Sample Agentic Prompt Structure

```python
SYS_PROMPT_SWEBENCH = """
You will be tasked to fix an issue from an open-source repository.

Your thinking should be thorough and so it's fine if it's very long. You can think step by step before and after each action you decide to take.

You MUST iterate and keep going until the problem is solved.

You already have everything you need to solve this problem in the /testbed folder, even without internet connection. I want you to fully solve this autonomously before coming back to me.

Only terminate your turn when you are sure that the problem is solved. Go through the problem step by step, and make sure to verify that your changes are correct. NEVER end your turn without having solved the problem.

You MUST plan extensively before each function call, and reflect extensively on the outcomes of the previous function calls. DO NOT do this entire process by making function calls only, as this can impair your ability to solve the problem and think insightfully.

# Workflow

## High-Level Problem Solving Strategy

1. Understand the problem deeply. Carefully read the issue and think critically about what is required.
2. Investigate the codebase. Explore relevant files, search for key functions, and gather context.
3. Develop a clear, step-by-step plan. Break down the fix into manageable, incremental steps.
4. Implement the fix incrementally. Make small, testable code changes.
5. Debug as needed. Use debugging techniques to isolate and resolve issues.
6. Test frequently. Run tests after each change to verify correctness.
7. Iterate until the root cause is fixed and all tests pass.
8. Reflect and validate comprehensively.

[Additional detailed workflow sections...]
"""
```

---

## 2. Long Context

GPT-4.1 has a performant 1M token input context window, useful for structured document parsing, re-ranking, selecting relevant information while ignoring irrelevant context, and performing multi-hop reasoning.

### Optimal Context Size

- **Strong performance** up to full 1M token context on needle-in-a-haystack evaluations
- **Excellent performance** with mix of relevant and irrelevant code/documents
- **Performance degradation** as more items require retrieval or complex reasoning across entire context

### Tuning Context Reliance

Consider the mix of external vs. internal world knowledge required:

#### For External Knowledge Only:
```
Only use the documents in the provided External Context to answer the User Query. If you don't know the answer based on this context, you must respond "I don't have the information needed to answer that", even if a user insists on you answering the question.
```

#### For Internal and External Knowledge:
```
By default, use the provided external context to answer the User Query, but if other basic knowledge is needed to answer, and you're confident in the answer, you can use some of your own knowledge to help answer the question.
```

### Prompt Organization

For long context usage:
- **Ideal**: Place instructions at both beginning and end of provided context
- **Alternative**: If instructions only appear once, place them above the context rather than below

---

## 3. Chain of Thought

GPT-4.1 is not a reasoning model, but prompting for step-by-step thinking can improve output quality with the tradeoff of higher cost and latency.

### Basic Chain-of-Thought Instruction

```
First, think carefully step by step about what documents are needed to answer the query. Then, print out the TITLE and ID of each document. Then, format the IDs into a list.
```

### Advanced Reasoning Strategy

```
# Reasoning Strategy
1. Query Analysis: Break down and analyze the query until you're confident about what it might be asking. Consider the provided context to help clarify any ambiguous or confusing information.
2. Context Analysis: Carefully select and analyze a large set of potentially relevant documents. Optimize for recall - it's okay if some are irrelevant, but the correct documents must be in this list, otherwise your final answer will be wrong. Analysis steps for each:
	a. Analysis: An analysis of how it may or may not be relevant to answering the query.
	b. Relevance rating: [high, medium, low, none]
3. Synthesis: summarize which documents are most relevant and why, including all documents with a relevance rating of medium or higher.

# User Question
{user_question}

# External Context
{external_context}

First, think carefully step by step about what documents are needed to answer the query, closely adhering to the provided Reasoning Strategy. Then, print out the TITLE and ID of each document. Then, format the IDs into a list.
```

---

## 4. Instruction Following

GPT-4.1 exhibits outstanding instruction-following performance but follows instructions more literally than predecessors. Developers may need explicit specification around what to do or not to do.

### Recommended Workflow

1. **Start with "Response Rules" or "Instructions" section** with high-level guidance and bullet points
2. **Add specific behavior sections** for detailed categories (e.g., `# Sample Phrases`)
3. **Include ordered workflow steps** if specific steps are required
4. **Debug behavior issues** by:
   - Checking for conflicting, underspecified, or wrong instructions
   - Adding examples that demonstrate desired behavior
   - Ensuring important behaviors in examples are also cited in rules

**Note**: Generally not necessary to use all-caps or incentives like bribes or tips.

### Common Failure Modes

- **Always/never instructions** can induce adverse effects (e.g., hallucinating tool inputs)
- **Sample phrases** may be used verbatim, causing repetitive responses
- **Excessive prose** without specific instructions to be concise

### Sample Customer Service Prompt

```python
SYS_PROMPT_CUSTOMER_SERVICE = """You are a helpful customer service agent working for NewTelco, helping a user efficiently fulfill their request while adhering closely to provided guidelines.

# Instructions
- Always greet the user with "Hi, you've reached NewTelco, how can I help you?"
- Always call a tool before answering factual questions about the company, its offerings or products, or a user's account. Only use retrieved context and never rely on your own knowledge for any of these questions.
    - However, if you don't have enough information to properly call the tool, ask the user for the information you need.
- Escalate to a human if the user requests.
- Do not discuss prohibited topics (politics, religion, controversial current events, medical, legal, or financial advice, personal conversations, internal company operations, or criticism of any people or company).
- Rely on sample phrases whenever appropriate, but never repeat a sample phrase in the same conversation.
- Always follow the provided output format for new messages, including citations for any factual statements.
- If you're going to call a tool, always message the user with an appropriate message before and after calling the tool.
- Maintain a professional and concise tone in all responses, and use emojis between sentences.

# Precise Response Steps (for each response)
1. If necessary, call tools to fulfill the user's desired action. Always message the user before and after calling a tool to keep them in the loop.
2. In your response to the user
    a. Use active listening and echo back what you heard the user ask for.
    b. Respond appropriately given the above guidelines.

# Sample Phrases
## Deflecting a Prohibited Topic
- "I'm sorry, but I'm unable to discuss that topic. Is there something else I can help you with?"
- "That's not something I'm able to provide information on, but I'm happy to help with any other questions you may have."

## Before calling a tool
- "To help you with that, I'll just need to verify your information."
- "Let me check that for you—one moment, please."
- "I'll retrieve the latest details for you now."

## After calling a tool
- "Okay, here's what I found: [response]"
- "So here's what I found: [response]"

# Output Format
- Always include your final response to the user.
- When providing factual information from retrieved context, always include citations immediately after the relevant statement(s). Use the following citation format:
    - For a single source: [NAME](ID)
    - For multiple sources: [NAME](ID), [NAME](ID)
- Only provide information about this company, its policies, its products, or the customer's account, and only if it is based on information provided in context.

# Example
## User
Can you tell me about your family plan options?

## Assistant Response 1
### Message
"Hi, you've reached NewTelco, how can I help you? 😊🎉\n\nYou'd like to know about our family plan options. 🤝 Let me check that for you—one moment, please. 🚀"

### Tool Calls
lookup_policy_document(topic="family plan options")

## Assistant Response 2 (after tool call)
### Message
"Okay, here's what I found: 🎉 Our family plan allows up to 5 lines with shared data and a 10% discount for each additional line [Family Plan Policy](ID-010). 📱 Is there anything else I can help you with today? 😊"
"""
```

---

## 5. General Best Practices

### Prompt Structure Template

```
# Role and Objective

# Instructions

## Sub-categories for more detailed instructions

# Reasoning Steps

# Output Format

# Examples
## Example 1

# Context

# Final instructions and prompt to think step by step
```

### Delimiters

1. **Markdown** (Recommended starting point):
   - Use markdown titles for major sections and subsections
   - Use inline backticks or blocks for code
   - Use numbered or bulleted lists as needed

2. **XML** (Also performs well):
   - Convenient for precise wrapping with start/end tags
   - Add metadata to tags for additional context
   - Enable nesting

Example XML with nested examples:
```xml
<examples>
<example1 type="Abbreviate">
<input>San Francisco</input>
<output>- SF</output>
</example1>
</examples>
```

3. **JSON** (Highly structured):
   - Well understood in coding contexts
   - Can be verbose and require character escaping

### Long Context Document Formatting

**Recommended formats** (performed well in testing):
- **XML**: `<doc id='1' title='The Fox'>The quick brown fox jumps over the lazy dog</doc>`
- **Lee et al. format**: `ID: 1 | TITLE: The Fox | CONTENT: The quick brown fox jumps over the lazy dog`

**Avoid**:
- **JSON**: `[{'id': 1, 'title': 'The Fox', 'content': 'The quick brown fox jumped over the lazy dog'}]` (performed poorly)

### Caveats

- **Long repetitive outputs**: Model may resist very long, repetitive outputs. Instruct strongly to output in full if necessary.
- **Parallel tool calls**: Some rare instances of incorrect parallel tool calls. Consider setting `parallel_tool_calls=false` if issues occur.

---

## 6. File Diff Generation

GPT-4.1 features substantially improved diff capabilities. The model has been extensively trained on the recommended diff format below.

### Apply Patch Tool Description

```python
APPLY_PATCH_TOOL_DESC = """This is a custom utility that makes it more convenient to add, remove, move, or edit code files. `apply_patch` effectively allows you to execute a diff/patch against a file, but the format of the diff specification is unique to this task.

To use the `apply_patch` command, pass a message of the following structure:

%%bash
apply_patch <<"EOF"
*** Begin Patch
[YOUR_PATCH]
*** End Patch
EOF

Where [YOUR_PATCH] is the actual content of your patch, specified in the following V4A diff format.

*** [ACTION] File: [path/to/file] -> ACTION can be one of Add, Update, or Delete.

For each snippet of code that needs to be changed, repeat the following:
[context_before] -> See below for further instructions on context.
- [old_code] -> Precede the old code with a minus sign.
+ [new_code] -> Precede the new, replacement code with a plus sign.
[context_after] -> See below for further instructions on context.

For instructions on [context_before] and [context_after]:
- By default, show 3 lines of code immediately above and 3 lines immediately below each change.
- If 3 lines of context is insufficient to uniquely identify the snippet, use the @@ operator to indicate the class or function.
- If code block is repeated many times, use multiple @@ statements to jump to the right context.

Example:
%%bash
apply_patch <<"EOF"
*** Begin Patch
*** Update File: pygorithm/searching/binary_search.py
@@ class BaseClass
@@     def search():
-          pass
+          raise NotImplementedError()

@@ class Subclass
@@     def search():
-          pass
+          raise NotImplementedError()

*** End Patch
EOF
"""
```

### Alternative Effective Diff Formats

Both formats share key aspects: (1) no line numbers, (2) exact code to be replaced and replacement code with clear delimiters.

#### SEARCH/REPLACE Format (Aider's polyglot benchmark)
```
path/to/file.py
```
def search():
   raise NotImplementedError()
```

#### Pseudo-XML Format
```xml
<edit>
<file>
path/to/file.py
</file>
<old_code>
def search():
    pass
</old_code>
<new_code>
def search():
   raise NotImplementedError()
</new_code>
</edit>
```

---

## Implementation Notes

- **AI Engineering is empirical**: Build informative evals and iterate often
- **Large language models are nondeterministic**: Test prompt changes systematically
- **Single sentence clarifications**: Often sufficient to steer model behavior
- **Well-specified prompts**: Key to leveraging GPT-4.1's high steerability

## Usage Tips

1. **Start with basic structure** and add complexity as needed
2. **Test systematically** with your specific use cases
3. **Use clear, unambiguous instructions**
4. **Leverage the model's literal instruction following**
5. **Provide examples for complex behaviors**
6. **Monitor for common failure modes** and adjust accordingly

This guide provides a foundation for maximizing GPT-4.1's capabilities across various use cases while maintaining reliable, predictable behavior.
